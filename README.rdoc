= ExecQueues

This is just me playing around with how to execute jobs on remote machines and get back the results via some communications channel (referred to as 'the storage backend' throughout the rest of this document). This toy currently supports messaging via Redis or MySQL. 

The idea is that you have some number of machines that you want to run jobs on (e.g. on a farm), and some clients that what to execute those methods which don't want to know the details of which machines the workers run on, how many of them there are, or how to transfer the inputs / outputs of those methods.

The <tt>worker.rb</tt> script acts as the worker, run this on your farm (or equivalent). The <tt>client.rb</tt> is an example client that constantly wants to find out what the value of various random multiples of pi are. It does this in a loop so I can test out performance.

== How to get it running
* Install and run a Redis server (this is used to store performance information atm regardless of which backend you use)
* Install and run a MySQL server if you want to try MySQL
* Run the <tt>create_db.sql</tt> script if you're trying MySQL
* Amend the <tt>Storage.backend=</tt> line in <tt>client.rb</tt> and <tt>worker.rb</tt> according to the storage backend you want to use
* Start some <tt>worker.rb</tt> and <tt>client.rb</tt> processes

If you do this correctly you should see the client's printing out something like this:
    [Sat Jun 05 18:15:59 +0100 2010] Submitted: #<Task:0x1014affb8 @id=272053, @state="unstarted", @type="CalculateMultipleOfPi", @input=759>
    [Sat Jun 05 18:15:59 +0100 2010] Received:  #<Task:0x1014aed70 @id=272053, @state="finished", @type="CalculateMultipleOfPi", @output=2384.46882135, @input=759>

    [Sat Jun 05 18:15:59 +0100 2010] Submitted: #<Task:0x1014ae550 @id=272054, @state="unstarted", @type="CalculateMultipleOfPi", @input=489>
    [Sat Jun 05 18:15:59 +0100 2010] Received:  #<Task:0x1014ad380 @id=272054, @state="finished", @type="CalculateMultipleOfPi", @output=1536.23880585, @input=489>

    ...

== Creating new types of tasks
To create a new task type put a <tt>.rb</tt> file in <tt>task_types</tt> that contains a class file that implements the <tt>execute</tt> method. For example:

    class LocalExec
      def execute(command)
        `#{command}`
      end
    end

or

    class WhatMachineIsThis
      def execute(parameter)
        `hostname`
      end
    end

Whatever the <tt>execute</tt> method returns will be what is passed back to the client that requested the job be executed.

== Redis implementation
The Redis implementation works like this:
* A task is created on the client, enqueued on <tt>unstarted</tt> queue (list) in Redis, the task is returned to the client with a unique <tt>id</tt>
* The client starts doing a <tt>blpop</tt> (blocking pop) on a queue called <tt>finished:[id]</tt>
* The workers have been doing a <tt>blpop</tt> (blocking pop) on the <tt>unstarted</tt> queue, so they pop the new task off
* Based on the <tt>type</tt> field the correct class is instantiated, the <tt>execute</tt> method is called, the work is done, and the result is saved in the <tt>output</tt> field of the task
* The task is enqueued on to a queue called <tt>finished:[id]</tt>
* The worker continues it's loop of doing <tt>blpop</tt> on <tt>unstarted</tt>, waiting for new jobs to run
* The <tt>blpop</tt> on <tt>finished:[id]</tt> returns the completed task to the client 

== MySQL implementation
A table, <tt>tasks</tt> is used to store the tasks.

The process works as follows:
* A task is created on the client, and is <tt>INSERT</tt>ed in to the table, the task is returned to the client with a unique <tt>id</tt>
* The client begins polling the <tt>tasks</tt> table, looking for that <tt>id</tt> with a state of <tt>finished</tt>
* The workers poll the <tt>tasks</tt> table looking for tasks with state <tt>unstarted</tt>
* When a worker finds such a task it issues an <tt>UPDATE</tt>, changing the state for that task to <tt>in_progress</tt> (this is to stop other workers trying to work on it)
* Based on the <tt>type</tt> field the correct class is instantiated, the <tt>execute</tt> method is called, the work is done, and the result is saved in the <tt>output</tt> field of the task
* An <tt>UPDATE</tt> is issued updating the row with the new <tt>output</tt> and the new state <tt>finished</tt>
* The worker continues it's loop of polling for new <tt>unstarted</tt> jobs
* The client, which has been polling the table, waiting for the job to change to the <tt>finished</tt> state returns the row, deletes the row from the database, and returns it to the script 

=== Ensuring each worker works on a different task
If several workers are polling the <tt>tasks</tt> table simultaneously they can both <tt>SELECT</tt> the same task/row, <tt>UPDATE</tt> that row (to state <tt>in_progress</tt>), and start work on the task.

The way I have prevented this is by using {optimistic locking}[link:http://c2.com/cgi/wiki?OptimisticLocking]. The process for a worker is like this:
* <tt>SELECT</tt>s a row with state <tt>unstarted</tt> (let's assume here the row has the value <tt>0</tt> in it's <tt>lock_version</tt> field)
* Create a task object from the row
* Change the <tt>state</tt> of the task object to <tt>in_progress</tt>
* Increment the object's <tt>lock_version</tt> field
* Issue an update for the row corresponding to the task object like this: <tt>UPDATE tasks SET state='in_progress', lock_version=1 WHERE id=1234 AND lock_version=0</tt>
* If the number of rows updated is 1 then the worker successfully got the row, if it's 0 then some other worker issued an update and got the task so the worker continues looking for a new task

== Performance
You can test the performance by running <tt>watch_performance.rb</tt>. Every second it will print the number of tasks that were completed in the last second.

The Redis system is about 15 times faster than the MySQL method (and uses almost no CPU when not busy) on my laptop. I suspect when there are more clients, and more jobs in the system the MySQL performance will fall even further (due worse locking problems).

Using a table of type <tt>MEMORY</tt> rather than <tt>INNODB</tt> does not make the MySQL implementation any faster. It could be that the lock contention could be improved by returning a random row (rather than the first row) to the client. This would require a full table scan (<tt>ORDER BY RAND</tt> means computing a random number for <i>every</i> row), but unless the table is very large (which it should never be) this should be no problem.

Running it all on my laptop (a 3 Ghz Macbook Pro) I get about 1,700 jobs/second with Redis, and about 110 jobs/second with MySQL. 

== Known limitations
* You can only give a single parameter to a task (the <tt>input</tt> field)
* The MySQL version limits the <tt>input</tt>s and <tt>output</tt>s to 256 characters
* If a worker dies while it is processing a job the client will wait forever for the job to be completed as there's no detection that a worker has died / failed leading to another worker processing the zombie job 

== Future plans
* Provide an 'out of comms channel' method of storing the input/ouputs of tasks (e.g. on NFS) for tasks where the input/output is large (multi-megabyte)
* Improve the MySQL performance
* Make it entirely transparent, through proxies that hide everything on the client side (so you just do <tt>CalculateMultipleOfPi.execute(42)</tt> on the client and get the response <i>as if</i> <tt>CalculateMultipleOfPi.execute(42)</tt> were running locally)
* Provide a way to run things asychronously
* Implement an easy way to execute a callback when a remote job finishes execution
* Specify connection details in a separate <tt>yaml</tt> configuration file
* Resubmit jobs where the worker has died (I'll probably never do that with this toy)